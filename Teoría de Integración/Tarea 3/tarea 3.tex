\documentclass{article}
\usepackage{hyperref}
\usepackage{Style}

\nocite{*} % Comentar si quiero citar
%\addbibresource{bibliografia.bib} % Quitar el comentado si quiero usar bibliografia

\begin{document}

\begin{minipage}{2.5cm}
    \includegraphics[width=2cm]{imagen_puc.jpg}
\end{minipage}
\begin{minipage}{14cm}
    {\sc Pontificia Universidad Católica de Chile\\
    Facultad de Matemáticas\\
    Departamento de Matemática\\
    Profesor: Gregorio Moreno -- Estudiante: Benjamín Mateluna}
\end{minipage}
\vspace{1ex}

{\centerline{\bf Teoría de Integración - MAT2534}
\centerline{\bf Tarea 3}}
\centerline{\bf 06 de junio de 2025}

\section*{Problema 1}
\begin{enumerate}
    \item Sea $t>0$, dado que $e^{-tx^{2}}$ es continua y positiva, se tiene que
    \begin{equation*}
        I=\int_{0}^{\infty}e^{-tx^{2}}dx=\int_{(0,\infty)}e^{-tx^{2}}d\lambda(x)
    \end{equation*}
    entonces, por independencia,
    \begin{align*}
        I^{2} &= \left(\int_{(0,\infty)}e^{-tx^{2}}d\lambda(x)\right)
        \left(\int_{(0,\infty)}e^{-ty^{2}}d\lambda(y)\right)
        =\int_{(0,\infty)}e^{-ty^{2}}\left(\int_{(0,\infty)}e^{-tx^{2}}d\lambda(x)\right)
        d\lambda(y) \\[2mm]
        &= \int_{(0,\infty)}\left(\int_{(0,\infty)}e^{-t(x^{2}+y^{2})}d\lambda(x)\right)d\lambda(y)
    \end{align*}
    Como la función $e^{-t(x^{2}+y^{2})}$ es continua y positiva, por tonelli vemos que
    \begin{equation*}
        I^{2}=\int_{(0,\infty)^{2}}e^{-t(x^{2}+y^{2})}(\lambda\otimes\lambda)dxdy
    \end{equation*}
    Consideremos el cambio de variables $x=rcos(\theta)$ y $y=rsen(\theta)$ con $r\in(0,\infty)$ y 
    $\theta\in(0,\frac{\pi}{2})$ con determinante jacobiano igual a $r$, luego
    \begin{equation*}
        I^{2}=\int_{(0,\infty)^{2}}e^{-t(x^{2}+y^{2})}(\lambda\otimes\lambda)dxdy
        =\int_{\left(0,\frac{\pi}{2}\right)\times(0,\infty)}re^{-tr^{2}}(\lambda\otimes\lambda)
        d\theta dr
    \end{equation*}
    notemos que $re^{-tr^{2}}$ es continua y positiva cuando $r\in(0,\infty)$, así, por tonelli
    vemos que
    \begin{equation*}
        I^{2}=\int_{\left(0,\frac{\pi}{2}\right)}\left(\int_{(0,\infty)}re^{-tr^{2}}
        dr\right)d\theta
        =\int_{0}^{\frac{\pi}{2}}\left(\int_{0}^{\infty}re^{-tr^{2}}
        dr\right)d\theta
        =\frac{\pi}{2}\int_{0}^{\infty}re^{-tr^{2}}dr
    \end{equation*}
    donde la segunda igualdad se debe a la continuidad y positividad. Utlizando el cambio de 
    variable $u=tr^{2}$, observamos que
    \begin{equation*}
        \int_{0}^{\infty}re^{-tr^{2}}dr=\frac{1}{2t}\int_{0}^{\infty}e^{-u}du
        =\frac{1}{2t}(-e^{-u})\Big|_{0}^{\infty}=\frac{1}{2t}<\infty
    \end{equation*}
    De este modo,
    \begin{equation*}
        I^{2}=\frac{\pi}{4t}
    \end{equation*}
    concluimos que $g(t)=\frac{1}{2}\sqrt{\frac{\pi}{t}}$.
    \newpage
    
    \item Consideremos la función $F(x,t)=e^{-x^{2}}cos(tx)$. Dado $t_{0}\in\R$ vemos que la 
    función $F(x,t_{0})$ es continua y por ende medible, además, $\pdv{F}{t}$ existe para todo
    $(x,t)\in\R^{2}$. Para $t=0$ notamos que
    \begin{equation*}
        f(0)=\int_{0}^{\infty}e^{-x^{2}}=\frac{\sqrt{\pi}}{2}
    \end{equation*}
    y por lo tanto $F(x,0)$ es integrable. Por otro lado,
    \begin{equation*}
        \abs{\pdv{F}{t}(x,t)}=\abs{-xe^{-x^{2}}sen(tx)}\leq \abs{x}e^{-x^{2}}=:g
    \end{equation*}
    es claro que $g$ es una función integrable, basta notar que su integral impropia es finita.
    Luego, la función $f$ es diferenciable y como $\abs{F(x,t)}\leq e^{-x^{2}}$ se tiene que
    \begin{align*}
        f'(t) &= \dv{}{t}\left(\int_{0}^{\infty}e^{-x^{2}}cos(tx)dx\right)
        =\dv{}{t}\left(\int_{(0,\infty)}e^{-x^{2}}cos(tx)d\lambda(x)\right)
        =\int_{(0,\infty)}\pdv{}{t}\left(e^{-x^{2}}cos(tx)\right)d\lambda(x) \\[2mm]
        &= \int_{(0,\infty)}-xe^{-x^{2}}sen(tx)d\lambda(x)=\int_{0}^{\infty}-xe^{-x^{2}}sen(tx)dx 
        \\[2mm]
        &=\frac{e^{-x^{2}}}{2}sen(tx)\Big|_{x=0}^{x=\infty}
        -\frac{t}{2}\int_{0}^{\infty}e^{-x^{2}}cos(tx)dx=-\frac{t}{2}f(t)
    \end{align*}
    Tenemos una EDO de variables separables $f'=-\frac{t}{2}f$ con condición inicial
    $f(0)=\frac{\sqrt{\pi}}{2}$. Luego
    \begin{equation*}
        \int\frac{df}{f}=\int-\frac{t}{2}dt
    \end{equation*}
    se sigue que
    \begin{equation*}
        log(f)=-\frac{t^{2}}{4}+C\hspace{4mm}\text{entonces}\hspace{4mm}f=e^{-\frac{t^{2}}{4}+C}
    \end{equation*}
    evaluando en la condición inicial vemos que
    \begin{equation*}
        f(t)=\frac{\sqrt{\pi}}{2}e^{-\frac{t^{2}}{4}}
    \end{equation*}
    para todo $t\in\R$.
    
    \item Sean $0<a<b<\infty$. Notemos que
    \begin{equation*}
        \frac{e^{-ax}-e^{-bx}}{x}=\int_{a}^{b}e^{-tx}dt
    \end{equation*}
    La función $e^{-tx}$ es continua y positiva, por tonelli vemos que
    \begin{align*}
        \int_{(0,\infty)\times(a,b)}e^{-tx}dtdx &= \int_{(a,b)}\int_{(0,\infty)}e^{-tx}dxdt
        =\int_{a}^{b}\int_{0}^{\infty}e^{-tx}dxdt=\int_{a}^{b}\int_{0}^{-\infty}-\frac{e^{u}}{t}
        dudt \\[2mm]
        &= \int_{a}^{b}-\frac{1}{t}e^{u}\Big|_{0}^{-\infty}dt=\int_{a}^{b}\frac{1}{t}dt
        =log\left(\frac{b}{a}\right)
    \end{align*}
    la segunda igualdad se debe a la continuidad y que la función $e^{-tx}$ es positiva. 
    Por otro lado tenemos que
    \begin{equation*}
        \int_{(0,\infty)\times(a,b)}e^{-tx}dtdx=\int_{(0,\infty)}\int_{(a,b)}e^{-tx}dtdx
        =\int_{0}^{\infty}\int_{a}^{b}e^{-tx}dtdx=h(a,b)
    \end{equation*}
    Por lo tanto $h(a,b)=log\left(\frac{b}{a}\right)$.
\end{enumerate}

\section*{Problema 2}
\begin{enumerate}
    \item El cambio de variables a coordenadas polares en $\R^{n}$, denotado por $\varphi_{n}$, 
    esta dado por
    \begin{align*}
        x_{n} &= rsen(\theta_{n-1}) \\
        x_{n-1} &= rcos(\theta_{n-1})sen(\theta_{n-2}) \\
        &\vdots \\
        x_{2} &= rcos(\theta_{n-1})cos(\theta_{n-2})\cdots cos(\theta_{2})sen(\theta_{1}) \\
        x_{1} &= rcos(\theta_{n-1})cos(\theta_{n-2})\cdots cos(\theta_{2})cos(\theta_{1})
    \end{align*}
    Afirmamos que el determinante jacobiano del cambio de variables es
    \begin{equation*}
        J_{\varphi_{n}}(r,\theta_{1},\cdots,\theta_{n-1})=r^{n-1}
        \prod_{i=2}^{n-1}(cos^{i-1}(\theta_{i}))
    \end{equation*}
    Procederemos por inducción sobre la dimensión. Para $n=1$ el resultado es inmediato, 
    supongamos que se tiene para $n$. Debemos probar el resultado para $n+1$. Expandiendo por
    cofactores notamos que
    \begin{align*}
        J_{\varphi_{n}} &= \begin{vmatrix}
            \pdv{x_{1}}{r} & \pdv{x_{1}}{\theta_{1}} & \cdots & \pdv{x_{1}}{\theta_{n-1}} & 
            \pdv{x_{1}}{\theta_{n}} \\[1mm]
            \vdots & \vdots & \ddots & \vdots & \vdots \\[1mm]
            \pdv{x_{n}}{r} & \pdv{x_{n}}{\theta_{1}} & \cdots & \pdv{x_{n}}{\theta_{n-1}} & 
            \pdv{x_{n}}{\theta_{n}} \\[2mm]
            \pdv{x_{n+1}}{r} & \pdv{x_{n+1}}{\theta_{1}} & \cdots & \pdv{x_{n+1}}{\theta_{n-1}} & 
            \pdv{x_{n+1}}{\theta_{n}}
        \end{vmatrix}=
        \begin{vmatrix}
            \pdv{x_{1}}{r} & \pdv{x_{1}}{\theta_{1}} & \cdots & \pdv{x_{1}}{\theta_{n-1}} & 
            \pdv{x_{1}}{\theta_{n}} \\[1mm]
            \vdots & \vdots & \ddots & \vdots & \vdots \\[1mm]
            \pdv{x_{n}}{r} & \pdv{x_{n}}{\theta_{1}} & \cdots & \pdv{x_{n}}{\theta_{n-1}} & 
            \pdv{x_{n}}{\theta_{n}} \\[2mm]
            sen(\theta_{n}) & 0 & \cdots & 0 & rcos(\theta_{n})
        \end{vmatrix} \\[2mm]
        &= (-1)^{n}sen(\theta_{n})\begin{vmatrix}
            \pdv{x_{1}}{\theta_{1}} & \cdots & \pdv{x_{1}}{\theta_{n-1}} & 
            \pdv{x_{1}}{\theta_{n}} \\[1mm]
            \vdots & \ddots & \vdots & \vdots \\[1mm]
            \pdv{x_{n}}{\theta_{1}} & \cdots & \pdv{x_{n}}{\theta_{n-1}} & 
            \pdv{x_{n}}{\theta_{n}}
        \end{vmatrix}+rcos(\theta_{n})\begin{vmatrix}
            \pdv{x_{1}}{r} & \pdv{x_{1}}{\theta_{1}} & \cdots & \pdv{x_{1}}{\theta_{n-1}} \\[1mm]
            \vdots & \vdots & \ddots & \vdots \\[1mm]
            \pdv{x_{n}}{r} & \pdv{x_{n}}{\theta_{1}} & \cdots & \pdv{x_{n}}{\theta_{n-1}}
        \end{vmatrix}
    \end{align*}
    Identificamos $(x_{1},\cdots,x_{n})$ con $(y_{1},\cdots,y_{n})$ y consideramos el cambio 
    de variable $\varphi_{n}$. Notemos que $\pdv{x_{i}}{\theta_{j}}=cos(\theta_{n})\pdv{y_{i}}
    {\theta_{j}}$ donde $1\leq i\leq n$ y $1\leq j\leq n-1$. Además, $\pdv{x_{i}}{\theta_{n}}
    =-sen(\theta_{n})r\pdv{y_{i}}{r}$ con $1\leq i\leq n$ y también $\pdv{x_{i}}{r}
    =cos(\theta_{n})\pdv{y_{i}}{r}$ para $1\leq i\leq n$. Luego,
    \begin{equation*}
        J_{\varphi_{n+1}} = (-1)^{n+1}rsen^{2}(\theta_{n})cos^{n-1}(\theta_{n})\begin{vmatrix}
            \pdv{y_{1}}{\theta_{1}} & \cdots & \pdv{y_{1}}{\theta_{n-1}} & 
            \pdv{y_{1}}{r} \\[1mm]
            \vdots & \ddots & \vdots & \vdots \\[1mm]
            \pdv{y_{n}}{\theta_{1}} & \cdots & \pdv{y_{n}}{\theta_{n-1}} & 
            \pdv{y_{n}}{r}
        \end{vmatrix}+rcos^{n+1}(\theta_{n})\begin{vmatrix}
            \pdv{y_{1}}{r} & \pdv{y_{1}}{\theta_{1}} & \cdots & \pdv{y_{1}}{\theta_{n-1}} \\[1mm]
            \vdots & \vdots & \ddots & \vdots \\[1mm]
            \pdv{y_{n}}{r} & \pdv{y_{n}}{\theta_{1}} & \cdots & \pdv{y_{n}}{\theta_{n-1}}
        \end{vmatrix}
    \end{equation*}
    Si permutamos $n-1$ columnas en la primera submatriz corresponde al jacobiano de $\varphi_{n}$,
    adicionalmente, la segunda submatriz es exactamente igual al jacobiano de $\varphi_{n}$. 
    Entonces
    \begin{align*}
        J_{\varphi_{n+1}} &= (-1)^{n+1}rsen^{2}(\theta_{n})cos^{n-1}(\theta_{n})(-1)^{n-1}
        J_{\varphi_{n}}+rcos^{n+1}(\theta_{n})J_{\varphi_{n}} \\[2mm]
        &= rcos^{n-1}(\theta_{n})J_{\varphi_{n}}(sen^{2}(\theta_{n})+cos^{2}(\theta_{n}))
        =rcos^{n-1}(\theta_{n})J_{\varphi_{n}}
    \end{align*}
    Usando la hipotesis inductiva, nos queda
    \begin{equation*}
        J_{\varphi_{n+1}}=r^{n}\prod_{i=2}^{n}(cos^{i-1}(\theta_{i}))
    \end{equation*}
    
    \item De la parte anterior consideramos el cambio de variable a coordenadas polares en 
    $\R^{n}$. Tenemos lo siguiente
    \begin{equation*}
        I=\int_{\R^{n}}g(\abs{x})d\lambda(x)=\int_{(0,\infty)\times(0,2\pi)\times
        (-\frac{\pi}{2},\frac{\pi}{2})^{n-2}}g(r)\abs{J_{\varphi_{n}}}drd\theta_{1}d\theta_{2}
        \cdots d\theta_{n-1}
    \end{equation*}
    como la función sigue siendo positiva despues de aplicar el cambio de variable, por tonelli 
    se sigue que
    \begin{align*}
        I &= \int_{(0,\infty)}\int_{(0,2\pi)}\int_{(-\frac{\pi}{2},\frac{\pi}{2})}\cdots
        \int_{(-\frac{\pi}{2},\frac{\pi}{2})}g(r)\abs{J_{\varphi_{n}}}d\theta_{n-1}\cdots 
        d\theta_{2}d\theta_{1}dr \\[2mm]
        &= 2\pi\prod_{i=2}^{n-1}\left(\int_{(-\frac{\pi}{2},\frac{\pi}{2})}cos^{i-1}(\theta)
        d\lambda(\theta)\right)\int_{(0,\infty)}g(r)r^{n-1}d\lambda(r) \\[2mm]
        &= 2\pi\prod_{i=2}^{n-1}\left(\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}cos^{i-1}(\theta)
        \hspace{1mm}d\theta\right)\int_{(0,\infty)}g(r)r^{n-1}d\lambda(r) \\[2mm]
        &= 2\pi\prod_{i=2}^{n-1}\left(\int_{0}^{\pi}sen^{i-1}(\theta)
        \hspace{1mm}d\theta\right)\int_{(0,\infty)}g(r)r^{n-1}d\lambda(r)
    \end{align*}
    en la última igualdad utilizamos que las variables son independientes entre sí, además, para
    ahorrar notación eliminamos los índices de las variables $\theta$. Definimos
    \begin{equation*}
        I(m)=\int_{0}^{\pi}sen^{m}(\theta)\hspace{1mm}d\theta
    \end{equation*}
    para $m\in\N_{0}$. Afirmamos que
    \begin{equation*}
        I(2m)=\pi\prod_{k=1}^{m}\frac{2k-1}{2k}\hspace{4mm}\text{y}\hspace{4mm}
        I(2m+1)=2\prod_{k=1}^{m}\frac{2k}{2k+1}
    \end{equation*}
    Probaremos lo anterior para el caso par, el otro caso es análogo. Sea $m=0$, el resultado es
    directo. Supongamos que el resultado se tiene para $m$. Utilizando integración por partes se 
    obtiene la recursión
    \begin{align*}
        \int_{0}^{\pi}sen^{2m+2}(\theta)\hspace{1mm}d\theta &= 
        -\frac{cos(\theta)sen^{2m-1}(\theta)}{2m+2}\Big|_{0}^{\pi}+\frac{2m+1}{2m+2}\int_{0}^{\pi}
        sen^{2m}(\theta)\hspace{1mm}d\theta=\frac{2m+1}{2m+2}\int_{0}^{\pi}sen^{2m}(\theta)
        \hspace{1mm}d\theta \\[2mm]
        &= \frac{2m+1}{2m+2}\cdot\pi\prod_{k=1}^{m}\frac{2k-1}{2k}
        =\pi\prod_{k=1}^{m+1}\frac{2k-1}{2k}
    \end{align*}
    Además observamos que
    \begin{equation*}
        I(2m-1)I(2m)=2\prod_{k=1}^{m-1}\frac{2k}{2k+1}\cdot\pi\prod_{k=1}^{m}\frac{2k-1}{2k}
        =2\pi\cdot\frac{2m-1}{2m}\cdot\prod_{k=1}^{m-1}\frac{2k-1}{2k+1}
        =2\pi\cdot\frac{2m-1}{2m}\cdot\frac{1}{2m-1}=\frac{\pi}{m}
    \end{equation*}
    Regresando al problema original, tenemos dos casos, $n-1$ es impar, es decir, $n-1=2k-1$, 
    entonces
    \begin{equation*}
        2\pi\prod_{i=2}^{n-1}\left(\int_{0}^{\pi}sen^{i-1}(\theta)
        \hspace{1mm}d\theta\right)
        =2\pi\prod_{i=2}^{2k-1}I(i-1)=2\pi\prod_{j=1}^{k-1}I(2j-1)I(2j)
        =2\pi\prod_{j=1}^{k-1}\frac{\pi}{j}=\frac{2\pi^{k}}{(k-1)!}
    \end{equation*}
    Supongamos que $n-1$ es par y por tanto $n-1=2k$, así
    \begin{align*}
        2\pi\prod_{i=2}^{n-1}\left(\int_{0}^{\pi}sen^{i-1}(\theta)
        \hspace{1mm}d\theta\right) &= 2\pi\prod_{i=2}^{2k}I(i-1)=2\pi\cdot I(2k-1)
        \prod_{i=2}^{2k-1}I(i-1)=\frac{2\pi^{k}}{(k-1)!}\cdot2\prod_{j=1}^{k-1}\frac{2j}{2j+1} 
        \\[2mm]
        &= 4\pi^{k}\cdot\prod_{j=1}^{k-1}\frac{2}{2j+1}
        =\frac{2^{k+1}\pi^{k}}{(2k-1)!!}
    \end{align*}
    Concluimos que
    \begin{equation*}
        I=S_{n-1}\int_{(0,\infty)}g(r)r^{n-1}d\lambda(r)
    \end{equation*}
\end{enumerate}

\section*{Problema 3}
\noindent En primer lugar, notemos que
\begin{equation*}
    I=\int_{[0,1]^{2}}\frac{1}{1-xy}(\lambda\otimes\lambda)(dxdy)=\int_{[0,1]^{2}}
    \sum_{n\geq1}(xy)^{n-1}(\lambda\otimes\lambda)(dxdy)
\end{equation*}
como $xy$ es positiva en $[0,1]^{2}$, por convergencia monótona y tonelli se sigue que
\begin{equation*}
    I=\sum_{n\geq1}\int_{[0,1]^{2}}(xy)^{n-1}(\lambda\otimes\lambda)(dxdy)
    =\sum_{n\geq1}\int_{[0,1]}\int_{[0,1]}x^{n-1}y^{n-1}dxdy
    =\sum_{n\geq1}\left(\int_{[0,1]}x^{n-1}dx\right)\left(\int_{[0,1]}y^{n-1}dy\right)
\end{equation*}
La última igualdad se debe a la independencia entre las variables. Por continuidad, vemos que
\begin{equation*}
    I=\sum_{n\geq1}\left(\int_{0}^{1}x^{n-1}dx\right)\left(\int_{0}^{1}y^{n-1}dy\right)
    =\sum_{n\geq1}\frac{1}{n^{2}}
\end{equation*}
Por otro lado, consideremos el cambio de variable $x=u+v$ e $y=u-v$ con determinante jacobiano 
igual a $2$, luego la nueva región de integración $\rr$ esta determinado por
\begin{equation*}
    \rr:=\left\{(u,v)\in\R^{2}:0\leq u\leq\frac{1}{2},-u\leq v\leq u\right\}\cup
    \left\{(u,v)\in\R^{2}:\frac{1}{2}\leq u\leq1,u-1\leq v\leq 1-u\right\}
\end{equation*}
Así,
\begin{equation*}
    I=\int_{\rr}\frac{2}{1-(u+v)(u-v)}(\lambda\otimes\lambda)(dxdy)
    =2\int_{\rr}\frac{1}{1-u^{2}+v^{2}}(\lambda\otimes\lambda)(dxdy)
\end{equation*}
Diremos que $\rr_{+}:=\rr\cap\{v\geq0\}$. Por simetría respecto a $v$, vemos que
\begin{equation*}
    I=4\int_{\rr_{+}}\frac{1}{1-u^{2}+v^{2}}(\lambda\otimes\lambda)(dxdy)
    =4\int_{[0,1]\times (R_{+})^{2}(u)}\frac{1}{1-u^{2}+v^{2}}(\lambda\otimes\lambda)(dxdy)
\end{equation*}
donde $(R_{+})^{2}(u)$ es la sección de $R_{+}$ respecto de $u$. Como $1-u^{2}+v^{2}$ es continua 
salvo un conjunto de medida nula y positiva, por tonelli se sigue que
\begin{equation*}
    I=4\int_{[0,1]}\int_{(R_{+})^{2}(u)}\frac{1}{1-u^{2}+v^{2}}d\lambda(v)d\lambda(u)
    =4\int_{0}^{1}\int_{0}^{f(u)}\frac{1}{1-u^{2}+v^{2}}dvdu
\end{equation*}
con $f$ función que describe el contorno superior de $\rr_{+}$ en función de u. Luego
\begin{equation*}
    I=4\left(\int_{0}^{\frac{1}{2}}\int_{0}^{u}\frac{1}{1-u^{2}+v^{2}}dvdu
    +\int_{\frac{1}{2}}^{1}\int_{0}^{1-u}\frac{1}{1-u^{2}+v^{2}}dvdu\right)
\end{equation*}
consideramos $a=\sqrt{1-u^{2}}$ que esta bien definido pues $0\leq u\leq1$, así
\begin{align*}
    I &= 4\left(\int_{0}^{\frac{1}{2}}\int_{0}^{u}\frac{1}{a^{2}+v^{2}}dvdu
    +\int_{\frac{1}{2}}^{1}\int_{0}^{1-u}\frac{1}{a^{2}+v^{2}}dvdu\right) \\[2mm]
    &= 4\left(\int_{0}^{\frac{1}{2}}\frac{1}{a}arctan\left(\frac{v}{a}\right)\Big|_{0}^{u}du
    +\int_{\frac{1}{2}}^{1}\frac{1}{a}arctan\left(\frac{v}{a}\right)\Big|_{0}^{1-u}du
    \right) \\[2mm]
    &= 4\left(\int_{0}^{\frac{1}{2}}\frac{1}{\sqrt{1-u^{2}}}arctan\left(\frac{u}{\sqrt{1-u^{2}}}
    \right)du+\int_{\frac{1}{2}}^{1}\frac{1}{\sqrt{1-u^{2}}}arctan\left(\frac{1-u}{\sqrt{1-u^{2}}}
    \right)du\right)=4(I_{1}+I_{2})
\end{align*}
Para $I_{1}$ integramos por partes, en efecto
\begin{align*}
    I_{1} &= arcsen(u)arctan\left(\frac{u}{\sqrt{1-u^{2}}}\right)\Big|_{0}^{\frac{1}{2}}
    -\int_{0}^{\frac{1}{2}}arcsen(u)\frac{1}{1+\frac{u^{2}}{1-u^{2}}}\frac{1}{\sqrt{1-u^{2}}}
    \frac{1}{1-u^{2}}du \\[2mm]
    &=\frac{\pi}{6}\cdot\frac{\pi}{6}-\int_{0}^{\frac{1}{2}}arcsen(u)\frac{1}{\sqrt{1-u^{2}}}du
    =\frac{\pi^{2}}{36}-\int_{0}^{\frac{\pi}{6}}t\hspace{1mm}dt=\frac{\pi^{2}}{36}
    -\frac{t^{2}}{2}\Big|_{0}^{\frac{\pi}{6}}=\frac{\pi^{2}}{72}
\end{align*}
donde realizamos el cambio de variable $t=arcsen(u)$. Por otra parte, para $I_{2}$ consideramos el
cambio de variable $u=cos(\theta)$ y entonces
\begin{align*}
    I_{2} &= -\int_{\frac{\pi}{3}}^{0}\frac{1}{sen(\theta)}arctan\left(
    \frac{1-cos(\theta)}{sen(\theta)}\right)sen(\theta)\hspace{1mm}d\theta
    =\int_{0}^{\frac{\pi}{3}}arctan\left(tan\left(\frac{\theta}{2}\right)\right)
    \hspace{1mm}d\theta \\[2mm]
    &= 2\int_{0}^{\frac{\pi}{6}}arctan(tan(w))\hspace{1mm}dw
    =2\int_{0}^{\frac{\pi}{6}}w\hspace{1mm}dw=w^{2}\Big|_{0}^{\frac{\pi}{6}}=\frac{\pi^{2}}{36}
\end{align*}
Luego
\begin{equation*}
    I=4(I_{1}+I_{2})=\left(\frac{\pi^{2}}{72}+\frac{\pi^{2}}{36}\right)=4\cdot\frac{3\pi^{2}}{72}
    =\frac{\pi^{2}}{6}
\end{equation*}

\section*{Problema 4}
\noindent Afirmamos que $f_{\alpha,\beta}$ es de variación acotada si y solo si $\alpha>\beta$. 
En efecto, supongamos que $\alpha\leq\beta$, definimos la sucesión $(x_{n})_{n\in\N}$ dada por
\begin{equation*}
    x_{n}:=\frac{1}{(\frac{\pi}{2} n)^{\frac{1}{\beta}}}
\end{equation*}
con $x_{0}:=0$. Notemos que $x_{n}\leq1$ para todo $n\in\N$ y además
\begin{equation*}
    f_{\alpha,\beta}(x_{n})=\frac{2^{\frac{\alpha}{\beta}}}{\pi^{\frac{\alpha}{\beta}}}\cdot
    \frac{1}{n^{\frac{\alpha}{\beta}}}sen\left(\frac{\pi}{2} n\right)
\end{equation*}
si $n$ es par entonces $f_{\alpha,\beta}(x_{n})=0$, de lo contrario,
\begin{equation*}
    f_{\alpha,\beta}(x_{n})=\frac{2^{\frac{\alpha}{\beta}}}{\pi^{\frac{\alpha}{\beta}}}\cdot
    \frac{1}{n^{\frac{\alpha}{\beta}}}
\end{equation*}
Consideramos la partición $\Pi_{n}=\{y_{i}\}_{i=0}^{n}$ donde $y_{0}=x_{0}$ e $y_{i}=x_{n+1-i}$, 
sin perdida de generalidad, supongamos que $n$ es impar, entoces $n=2k-1$, luego
\begin{align*}
    V(f,\Pi_{n}) &= \sum_{i=1}^{n}\abs{f(y_{i})-f(y_{i-1})}\geq\sum_{j=1}^{k}\abs{f(x_{2j-1})}
    =\sum_{j=1}^{k}\frac{2^{\frac{\alpha}{\beta}}}{\pi^{\frac{\alpha}{\beta}}}\cdot
    \frac{1}{(2j-1)^{\frac{\alpha}{\beta}}}=\frac{2^{\frac{\alpha}{\beta}}}
    {\pi^{\frac{\alpha}{\beta}}}\sum_{j=1}^{k}\frac{1}{(2j-1)^{\frac{\alpha}{\beta}}} \\
    &\geq\frac{2^{\frac{\alpha}{\beta}}}
    {\pi^{\frac{\alpha}{\beta}}}\sum_{j=1}^{k}\frac{1}{(2j)^{\frac{\alpha}{\beta}}}
    =\frac{1}{\pi^{\frac{\alpha}{\beta}}}\sum_{j=1}^{k}\frac{1}{j^{\frac{\alpha}{\beta}}}
\end{align*}
como $\alpha\leq\beta$, la última suma diverge cuando $n\to\infty$ y por lo tanto 
$f_{\alpha,\beta}$ no es de variación acotada.

\vspace{2mm}
\noindent Supongamos que $\alpha>\beta$. Definimos $f_{n}:=\I_{\{0\}\cup\left[\frac{1}{n},1\right]}
f_{\alpha,\beta}$. Es claro que $f_{n}$ converge puntualmente a $f_{\alpha,\beta}$, así
\begin{equation*}
    V(f,[0,1])\leq\liminf\limits_{n\to\infty}V(f_{n},[0,1])
\end{equation*}
Dado $n\in\N$, notemos que $V(f_{n},[0,1])=V(f_{n},\left[0,\frac{1}{n}\right])
+V(f_{n},\left[\frac{1}{n},1\right])=V(f_{n},\left[\frac{1}{n},1\right])$. La función $f_{n}$ se 
puede extender de modo que sea diferenciable en $(\frac{1}{n}-\varepsilon,1+\varepsilon)$ con 
$\varepsilon>0$ suficientemente pequeño. Luego, se tiene que
\begin{equation*}
    V\left(f_{n},\left[\frac{1}{n},1\right]\right)\leq\int_{\frac{1}{n}}^{1}
    \abs{f_{\alpha,\beta}'(x)}dx\leq\int_{0}^{1}\abs{f_{\alpha,\beta}'(x)}dx
\end{equation*}
donde la segunda integral es impropia, que esta bien definida ya que $f_{\alpha,\beta}'$ es 
Riemann integrable en todo intervalo de la forma $[b,1]$ con $b>0$, por continuidad. Veamos que
\begin{equation*}
    \int_{0}^{1}\abs{f_{\alpha,\beta}'(x)}dx=\int_{0}^{1}\abs{\alpha x^{\alpha-1}sen(x^{-\beta})
    -\beta x^{\alpha-\beta-1}cos(x^{-\beta})}\hspace{1mm}dx\leq\alpha\int_{0}^{1}x^{\alpha-1}
    \hspace{1mm}dx+\beta\int_{0}^{1}x^{\alpha-\beta-1}\hspace{1mm}dx
\end{equation*}
La integral que esta a la izquierda es convergente, ya que $\alpha>0$ y por ende $\alpha-1>-1$. Por 
otro lado, como $\alpha>\beta$, se tiene que $\alpha-\beta-1>-1$ lo que implica que la integral de 
la derecha es convergente. De este modo,
\begin{equation*}
    V(f,[0,1])\leq\liminf\limits_{n\to\infty}V(f_{n},[0,1])\leq
    \int_{0}^{1}\abs{f_{\alpha,\beta}'(x)}dx<\infty
\end{equation*}
Concluimos que $f_{\alpha,\beta}$ es de variación acotada.

\section*{Problema 5}
\begin{lema}
    Sea $g:[a,b]\to\R$ una función creciente y absolutamente continua. Sea $E\subseteq[a,b]$ un
    conjunto de medida nula, entonces $\lambda(g(E))=0$.
\end{lema}
\begin{dem}
    Sea $\varepsilon>0$, como $E$ es medible, existe $G\supseteq E$ abierto tal que 
    $\lambda(G)<\delta$ para todo $\delta>0$, como $g$ es creciente y absolutamente continua, 
    existe $\delta>0$ y $G$ abierto tal que $\lambda(g(E))\leq\lambda(g(G))<\varepsilon$. Dado que
    $\varepsilon$ es arbitrario, concluimos que $\lambda(g(E))=0$.
\end{dem}

\noindent Sea $I\subseteq[a,b]$ un intervalo con extremos $c<d$. Como $g$ es continua y creciente
$g(I)=(g(c),g(d))$, además, por absoluta continuidad y TFC se sigue que
, como $g$ es absolutamente continua, por TFC 
se sigue que
\begin{equation*}
    \lambda(g(I))=\lambda((g(c),g(d)))=g(d)-g(c)=\int_{(c,d)}g'd\lambda
\end{equation*}
Sea $(I_{n})_{n}$ intervalos disjuntos de a pares contenidos en $[a,b]$, entonces como $g$ es 
estrictamente creciente, en particular, es inyectiva lo que implica que $g(I_{n})$ son disjuntos 
de a pares. Notemos que
\begin{equation*}
    \lambda\left(g\left(\bigcup_{n\in\N}I_{n}\right)\right)
    =\lambda\left(\bigcup_{n\in\N}g(I_{n})\right)=\sum_{n\in\N}\lambda(g(I_{n}))
    =\sum_{n\in\N}\int_{I_{n}}g'd\lambda=\int\sum_{n\in\N}\I_{n}g'd\lambda
    =\int_{\bigcup_{n\in\N}I_{n}}g'd\lambda
\end{equation*}
en donde para intercambiar la serie con la integral usamos teorema de convergencia dominada. Como
todo abierto se puede escribir como unión numerable de intervalos abiertos disjuntos de a pares,
lo anterior prueba el argumento para abiertos $U\subseteq[a,b]$.

\vspace{2mm}
\noindent Sea $G\in G_{\delta}$, existen $(U_{n})_{n}$ abiertos tales que
\begin{equation*}
    G=\bigcap_{n\in\N}U_{n}
\end{equation*}
sin perdida de generalidad podemos suponer que estos abiertos estan encajonados. Como $[a,b]$ es
compacto entonces $g([a,b])$ es compacto y entonces $g(U_{1})<\infty$, así
\begin{equation*}
    \lambda(g(G))=\lambda\left(g\left(\bigcap_{n\in\N}U_{n}\right)\right)
    =\lambda\left(\bigcap_{n\in\N}g(U_{n})\right)=\lim\limits_{n\to\infty}\lambda(g(U_{n}))
    =\lim\limits_{n\to\infty}\int_{U_{n}}g'd\lambda=\int_{G}g'd\lambda
\end{equation*}
donde la última igualdad se debe al teorema de convergencia dominada, notando que $\I_{U_{n}}$ 
converge a $\I_{G}$. 

\vspace{2mm}
\noindent Sea $E\subseteq[a,b]$ medible, existe $G\in G_{\delta}$ tal que 
$\lambda(G\setminus E)=0$, por el lema tenemos que $\lambda(g(G\setminus E))=0$, como $g$ es 
continua, inyectiva y $[a,b]$ es compacto se tiene que $\lambda(g(E))=\lambda(g(G))$, entonces
\begin{equation*}
    \lambda(g(E))=\lambda(g(G))=\int_{G}g'\hspace{1mm}d\lambda=\int_{E}g'\hspace{1mm}d\lambda
    +\int_{G\setminus E}g'\hspace{1mm}d\lambda=\int_{E}g'\hspace{1mm}d\lambda
\end{equation*}

%($g(E)$ es medible para $E$ medible, g manda medida nula en medida nula)

%\printbibliography % Quitar el comentado si quiero usar bibliografia

\end{document}
